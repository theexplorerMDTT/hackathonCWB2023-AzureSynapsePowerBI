{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transform data by using Spark\n",
        "\n",
        "This notebook gets the zip file in Azure Blob Storage and unzip it\n",
        "\n",
        "## Set variables"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "\r\n",
        "# Variable for unique folder name\r\n",
        "folderName = uuid.uuid4()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkb6mji41",
              "session_id": "8",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-05-14T18:43:13.2308013Z",
              "session_start_time": null,
              "execution_start_time": "2023-05-14T18:43:13.3426651Z",
              "execution_finish_time": "2023-05-14T18:43:13.5058728Z",
              "spark_jobs": null,
              "parent_msg_id": "45ece1ee-2f29-42b1-8c53-5ff0f12b1924"
            },
            "text/plain": "StatementMeta(sparkb6mji41, 8, 3, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "connection_string = 'DefaultEndpointsProtocol=https;AccountName=datalakeb6mji41;AccountKey=xUmUxSo+LluK7032QEc5WFzaTd4pirtfOqJpbKSVk45AbgVu3RV7u2KSOwXUKTLYx79r7jBjG/ms+AStkXP1Iw==;EndpointSuffix=core.windows.net'"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkb6mji41",
              "session_id": "8",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-05-14T18:43:15.9510266Z",
              "session_start_time": null,
              "execution_start_time": "2023-05-14T18:43:16.0599063Z",
              "execution_finish_time": "2023-05-14T18:43:16.2336888Z",
              "spark_jobs": null,
              "parent_msg_id": "b9ebb055-10c9-4963-ab11-3c2e5b40a9b5"
            },
            "text/plain": "StatementMeta(sparkb6mji41, 8, 4, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load source data\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient, BlobClient\n",
        "import zipfile\n",
        "# Create a connection to your Azure Blob Storage account\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_name = 'files'\n",
        "zip_file_path = '/data/enrollmentdb.zip'\n",
        "\n",
        "import datetime\n",
        "# Generate a unique folder name using a timestamp\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "folder_name = f\"converteddata_{timestamp}\"\n",
        "\n",
        "# Specify the path where to extract the contents of the zip file\n",
        "extract_path = f\"{folder_name}/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkb6mji41",
              "session_id": "8",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-05-14T18:43:22.7321929Z",
              "session_start_time": null,
              "execution_start_time": "2023-05-14T18:43:22.8551874Z",
              "execution_finish_time": "2023-05-14T18:43:23.0225096Z",
              "spark_jobs": null,
              "parent_msg_id": "ca51627d-4a54-4f08-8602-4370c7a85364"
            },
            "text/plain": "StatementMeta(sparkb6mji41, 8, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the zip file to a local temporary file then extract it"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the zip file to a local temporary file\r\n",
        "local_zip_path = 'temp.zip'\r\n",
        "blob_client = blob_service_client.get_blob_client(container=container_name, blob=zip_file_path)\r\n",
        "with open(local_zip_path, 'wb') as file:\r\n",
        "    file.write(blob_client.download_blob().readall())"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkb6mji41",
              "session_id": "8",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-05-14T18:43:28.5082249Z",
              "session_start_time": null,
              "execution_start_time": "2023-05-14T18:43:28.6349652Z",
              "execution_finish_time": "2023-05-14T18:43:29.7233608Z",
              "spark_jobs": null,
              "parent_msg_id": "d831b2aa-6fbc-4679-a024-5d2910ef393a"
            },
            "text/plain": "StatementMeta(sparkb6mji41, 8, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkb6mji41",
              "session_id": "8",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-05-14T18:43:32.3321572Z",
              "session_start_time": null,
              "execution_start_time": "2023-05-14T18:43:32.4549317Z",
              "execution_finish_time": "2023-05-14T18:43:32.9870711Z",
              "spark_jobs": null,
              "parent_msg_id": "2e3eacae-a56d-4d10-8ea9-e31555f5934a"
            },
            "text/plain": "StatementMeta(sparkb6mji41, 8, 7, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the unzipped data\r\n",
        "\r\n",
        "The unzipped files are in Microsoft Access. It will be saved on Azure Blob Storage for further transformation.\r\n",
        "Due to errors while handling converting to csv (parsing errors, dependencies installation, this conversion will be done locally)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient, BlobClient\r\n",
        "import os\r\n",
        "import uuid\r\n",
        "\r\n",
        "\r\n",
        "# Create a connection to your Azure Blob Storage account\r\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\r\n",
        "\r\n",
       
        "\r\n",
        "# Specify the name of your container\r\n",
        "container_name = 'files'\r\n",
        "\r\n",
        "# Iterate over the files in the extract_path directory\r\n",
        "for file_name in os.listdir(extract_path):\r\n",
        "    # Construct the source file path\r\n",
        "    source_file_path = os.path.join(extract_path, file_name)\r\n",
        "\r\n",
       
        "    \r\n",
        "    # Modify the file name with the unique identifier\r\n",
        "    new_file_name = f\"{file_name}\"\r\n",
        "    \r\n",
        "    # Check if the source file path exists\r\n",
        "    if os.path.exists(source_file_path):\r\n",
        "        # Create a BlobClient for the file\r\n",
        "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=new_file_name)\r\n",
        "        \r\n",
        "        # Upload the file to Azure Blob Storage\r\n",
        "        with open(source_file_path, \"rb\") as file:\r\n",
        "            blob_client.upload_blob(file)\r\n",
        "        \r\n",
        "        print(f\"File {file_name} uploaded to Azure Blob Storage.\")\r\n",
        "    else:\r\n",
        "        print(f\"Source file {source_file_path} does not exist.\")\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkb6mji41",
              "session_id": "8",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-05-14T18:43:51.626138Z",
              "session_start_time": null,
              "execution_start_time": "2023-05-14T18:43:51.7426681Z",
              "execution_finish_time": "2023-05-14T18:43:52.8546743Z",
              "spark_jobs": null,
              "parent_msg_id": "4fc9623a-3521-4109-9eec-14bbcd67a5cf"
            },
            "text/plain": "StatementMeta(sparkb6mji41, 8, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ENROLL2022_20221114.mdb uploaded to Azure Blob Storage.\nFile ENROLL2022ReadMe_20230303.docx uploaded to Azure Blob Storage.\nFile ENROLL2022_20221114.accdb uploaded to Azure Blob Storage.\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}